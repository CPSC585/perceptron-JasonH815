{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "### Name: Jason Hellwig\n",
    "### CWID: 894789627"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code take from assignment specificiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "class Node(object):\n",
    "    \"\"\"\n",
    "    Base object for all inputs and outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, value, grad):\n",
    "        self.value = value\n",
    "        self.gradient = grad\n",
    "\n",
    "\n",
    "class MultiplyNode(object):\n",
    "    \"\"\"\n",
    "    Multiplies two inputs\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.output = Node(self.x1.value * self.x2.value, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self):\n",
    "        self.x1.gradient = self.x2.value * self.output.gradient\n",
    "        self.x2.gradient = self.x1.value * self.output.gradient\n",
    "\n",
    "\n",
    "class AddNode(object):\n",
    "    \"\"\"\n",
    "    Adds two inputs x1 and x2.\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.output = Node(self.x1.value + self.x2.value, 0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self):\n",
    "        self.x1.gradient = 1 * self.output.gradient\n",
    "        self.x2.gradient = 1 * self.output.gradient\n",
    "\n",
    "\n",
    "class SigmoidNode(object):\n",
    "    \"\"\"\n",
    "    Adds a sigmoid non-linearity to a single input\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.output = Node(1 / (1 + np.exp(-1 * self.x.value)), 0.0)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self):\n",
    "        s = 1 / (1 + np.exp(-1 * self.x.value))\n",
    "        self.x.gradient = (s * (1 - s)) * self.output.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified perceptron class\n",
    "### Generalized for an arbitrary amount of imput weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron(object):\n",
    "    def __init__(self, inputs, alpha=0.001):\n",
    "        ### Hyper parameters\n",
    "        self.alpha = alpha\n",
    "\n",
    "        ### Initializing weights/bias to a random float between -1 and 1.\n",
    "        self.w = [Node(np.random.uniform(-1, 1), 0.0) for x in inputs]\n",
    "        self.w.append(Node(np.random.uniform(-1, 1), 0.0))  # bias term\n",
    "\n",
    "        ### Input and Output variables\n",
    "        self.x = [Node(x, 0.0) for x in inputs]\n",
    "        self.x.append(Node(1, 0.0))  # bias term\n",
    "\n",
    "        ### Initialize operators nodes required\n",
    "        ### for processing the inputs within a perceptron\n",
    "        self.initialize_operators()\n",
    "\n",
    "    def initialize_operators(self):\n",
    "        self.mul = [MultiplyNode() for node in self.w]\n",
    "        self.add = [AddNode() for node in self.w[:-1]]  # there is n-1 add operators\n",
    "        self.sigmoid = SigmoidNode()\n",
    "\n",
    "    def forward(self, newInput=None):\n",
    "        # ability to update input value if input is from hidden layer\n",
    "        if newInput:\n",
    "            for i in range(len(newInput)):\n",
    "                self.x[i].value = newInput[i]\n",
    "\n",
    "        # do the multiplications\n",
    "        multiplications = []\n",
    "        for i in range(len(self.w)):\n",
    "            multiplications.append(self.mul[i].forward(self.w[i], self.x[i]))\n",
    "\n",
    "        # do the additions\n",
    "        addition_result = multiplications[0]\n",
    "        for i in range(len(multiplications) - 1): # there is n-1 add operators\n",
    "            addition_result = self.add[i].forward(addition_result, multiplications[i + 1])\n",
    "\n",
    "        # return the final sigmoid result\n",
    "        return self.sigmoid.forward(addition_result)\n",
    "\n",
    "    def backward(self):\n",
    "        # back-propogate the errors\n",
    "        self.sigmoid.backward()\n",
    "        [op.backward() for op in self.add]\n",
    "        [op.backward() for op in self.mul]\n",
    "\n",
    "    def update(self):\n",
    "        for w in self.w:\n",
    "            w.value -= self.alpha * w.gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nerual Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, x1, x2, alpha=0.001):\n",
    "        ### Hyper parameters\n",
    "        self.alpha = alpha\n",
    "\n",
    "        self.p1 = Perceptron([x1, x2], alpha=alpha)\n",
    "        self.p2 = Perceptron([self.p1.forward().value], alpha=alpha)\n",
    "\n",
    "    def forward(self):\n",
    "        return self.p2.forward([self.p1.forward().value])\n",
    "\n",
    "    def backward(self):\n",
    "        self.p2.sigmoid.output.gradient = -2 * (target - self.p2.sigmoid.output.value)\n",
    "        self.p2.backward()\n",
    "        self.p1.sigmoid.output.gradient = self.p2.w[0].gradient  # propagate back the the weight from 2nd perceptron\n",
    "        self.p1.backward()\n",
    "\n",
    "    def update(self):\n",
    "        self.p2.update()\n",
    "        self.p1.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of 2 Perceptron Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pass 1, value: 0.5271674916938318\n",
      "pass 1, hidden-value: 0.5974372945096734\n",
      "pass 10000, value: 0.3481972639817006\n",
      "pass 10000, hidden-value: 0.5784757495611493\n",
      "weights:\n",
      "wx1_p1: 0.608744457018\n",
      "wx2_p1: 0.539946966537\n",
      "w-bias_p1: 0.789504393056738\n",
      "wp1_p2: -0.36614788694707817\n",
      "w-bias_p2: -0.4151651209798792\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(0.11, -1.0, alpha=0.1)\n",
    "# number of iterations\n",
    "N = 10000\n",
    "# expected output\n",
    "target = 0.3481972639817\n",
    "\n",
    "nn.forward()\n",
    "print('pass 1, value: %s' % nn.p2.sigmoid.output.value)\n",
    "print('pass 1, hidden-value: %s' % nn.p1.sigmoid.output.value)\n",
    "\n",
    "for i in range(N):\n",
    "    # Step 1. Forward Pass\n",
    "    nn.forward()\n",
    "    # Step 2. Calculate Loss. -2 * (y - output) is the gradient of output w.r.t\n",
    "    # square loss function.\n",
    "    # nn.sigmoid.output.gradient = -2 * (target - nn.sigmoid.output.value)\n",
    "    # Step 3. Backward Pass\n",
    "    nn.backward()\n",
    "    # Step 4. Update Weights and Bias\n",
    "    nn.update()\n",
    "\n",
    "print('pass %d, value: %s' % (N, nn.p2.sigmoid.output.value))\n",
    "print('pass %d, hidden-value: %s' % (N, nn.p1.sigmoid.output.value))\n",
    "print('weights:')\n",
    "print('wx1_p1: %s' % nn.p1.w[0].value)\n",
    "print('wx2_p1: %s' % nn.p1.w[1].value)\n",
    "print('w-bias_p1: %s' % nn.p1.w[2].value)\n",
    "print('wp1_p2: %s' % nn.p2.w[0].value)\n",
    "print('w-bias_p2: %s' % nn.p2.w[1].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- Most of the learning seems to be happening in the second perceptron\n",
    "- The output value of the first percepton doesn't change as much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
